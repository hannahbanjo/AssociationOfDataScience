{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannahbanjo/AssociationOfDataScience/blob/main/ai_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build-An-Agent**"
      ],
      "metadata": {
        "id": "N69_dWJFTIlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*In* this notebook, we'll walk through the process of building an AI agent that can generate images from a text prompt using a pre-trained Stable Diffusion model. Then, the agent will analyze the generated image using a pre-trained object detection model. This activity will allow us to see how an AI agent can seamlessly integrate multiple machine learning pipelines, from image generation to object detection, to create a powerful tool for visual content creation and analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "eC7CGKJmRa-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the image"
      ],
      "metadata": {
        "id": "H0g26VfOWew7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's begin by importing the libraries we need. We'll use diffusers for image generation, torch for GPU support, PIL for image manipulation, and transformers for object detection."
      ],
      "metadata": {
        "id": "nIdXrPz1RgV1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvgDubXDXbUU"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we generate an image based on the prompt we provide and save it to the file generated_image.jpg"
      ],
      "metadata": {
        "id": "OiYH8dayRk7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: You may have to change the runtime type if you encounter a run time error. Go to runtime --> change runtime type --> T4 GPU"
      ],
      "metadata": {
        "id": "YvP6MjctRndV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model (Stable Diffusion)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\", torch_dtype=torch.float32)\n",
        "\n",
        "# Move the pipeline to GPU (if available)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Generate image based on text prompt\n",
        "prompt = \"A meadow with a dog and cat\"\n",
        "image = pipe(prompt).images[0]\n",
        "\n",
        "# Save the generated image to a file\n",
        "image.save(\"/content/generated_image.jpg\")\n",
        "\n",
        "# Display the generated image\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")  # Turn off axis\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vyx6DRZpXfEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Object Detection"
      ],
      "metadata": {
        "id": "yGijKpcMWn0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will import the necessary libraries for performing object detection on the generated image. We'll use the transformers library to load a pre-trained object detection model."
      ],
      "metadata": {
        "id": "enhbbi33SAQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from PIL import Image, ImageDraw"
      ],
      "metadata": {
        "id": "7ttp1rf7Xg17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we perform object detection, output the identified objects, and display their respective locations within the image."
      ],
      "metadata": {
        "id": "wGpnRXoaSJcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load pre-trained object detection model\n",
        "image_analyzer = pipeline(\"object-detection\")\n",
        "\n",
        "# Load the image (use your generated image)\n",
        "image = Image.open(\"/content/generated_image.jpg\")\n",
        "\n",
        "# Analyze the image for object detection (with adjusted threshold)\n",
        "result = image_analyzer(image, threshold=0.3)  # Adjust threshold to your preference\n",
        "\n",
        "# Print the result to inspect the structure\n",
        "print(result)"
      ],
      "metadata": {
        "id": "sknM17yCXiB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the object detection process clearer, let's add bounding boxes around the detected objects, allowing us to visualize their locations more easily."
      ],
      "metadata": {
        "id": "fFZqxwG5SbFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize detected objects\n",
        "draw = ImageDraw.Draw(image)\n",
        "\n",
        "# Iterate over each detection result in the returned list\n",
        "for detection in result:\n",
        "    score = detection[\"score\"]\n",
        "    label = detection[\"label\"]\n",
        "    box = detection[\"box\"]  # This should be in the format {'xmin': value, 'ymin': value, 'xmax': value, 'ymax': value}\n",
        "\n",
        "    # Extract the bounding box coordinates from the dictionary\n",
        "    left = int(box['xmin'])\n",
        "    top = int(box['ymin'])\n",
        "    right = int(box['xmax'])\n",
        "    bottom = int(box['ymax'])\n",
        "\n",
        "    # Draw the bounding box if the score is above the threshold\n",
        "    if score > 0.5:  # You can adjust the confidence threshold\n",
        "        draw.rectangle([left, top, right, bottom], outline=\"red\", width=3)\n",
        "        draw.text((left, top), str(label), fill=\"red\")\n",
        "\n",
        "# Display the image with bounding boxes\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "arFsT5mkSGZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment with different confidence thresholds to see how it affects which objects are detected.\n"
      ],
      "metadata": {
        "id": "ixwnu5XGTrff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add your code here"
      ],
      "metadata": {
        "id": "-X_zCaLjWKb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create your own prompt! How well does the object detection do with more/less objects in the image?"
      ],
      "metadata": {
        "id": "q9-gPzP4WOZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add your code here"
      ],
      "metadata": {
        "id": "Eefp6IRwWaJI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}