{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannahbanjo/AssociationOfDataScience/blob/main/Datathon_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "#Datathon Workshop: Complete Guide\n",
        "### Data Cleaning â€¢ EDA â€¢ Business Questions â€¢ Stakeholder Presentations\n",
        "\n",
        "**Workshop Goal:** Learn the essential skills to succeed in datathons by mastering data preparation, exploratory analysis, business problem-solving, and presentation techniques.\n",
        "\n",
        "---\n",
        "\n",
        "##Table of Contents\n",
        "1. [Setup & Imports](#setup)\n",
        "2. [Data Cleaning](#cleaning)\n",
        "3. [Exploratory Data Analysis (EDA)](#eda)\n",
        "4. [Answering Business Questions](#business)\n",
        "5. [Creating Non-Technical Presentations](#presentations)\n",
        "6. [Datathon Best Practices](#best-practices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBCCq6PdHgqX"
      },
      "source": [
        "<a id='setup'></a>\n",
        "## 1. Setup & Imports\n",
        "\n",
        "First, let's import all the libraries we'll need for data manipulation, visualization, and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nWRSOVdHgqY"
      },
      "outputs": [],
      "source": [
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Statistical analysis\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgBd1cCQHgqZ"
      },
      "source": [
        "### Generate Sample Dataset\n",
        "\n",
        "For this workshop, we'll create a realistic e-commerce dataset with common data quality issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL6_nPfIHgqZ"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate sample e-commerce data\n",
        "n_records = 1000\n",
        "\n",
        "# Create base data\n",
        "data = {\n",
        "    'customer_id': range(1, n_records + 1),\n",
        "    'age': np.random.randint(18, 75, n_records),\n",
        "    'gender': np.random.choice(['Male', 'Female', 'Other'], n_records, p=[0.48, 0.48, 0.04]),\n",
        "    'purchase_amount': np.random.gamma(2, 50, n_records),\n",
        "    'items_purchased': np.random.poisson(3, n_records),\n",
        "    'days_since_last_purchase': np.random.exponential(30, n_records),\n",
        "    'customer_segment': np.random.choice(['Premium', 'Regular', 'New'], n_records, p=[0.15, 0.6, 0.25]),\n",
        "    'marketing_channel': np.random.choice(['Email', 'Social Media', 'Direct', 'Referral'], n_records),\n",
        "    'product_category': np.random.choice(['Electronics', 'Clothing', 'Home', 'Books', 'Sports'], n_records),\n",
        "    'satisfaction_score': np.random.randint(1, 6, n_records),\n",
        "    'discount_used': np.random.choice([True, False], n_records, p=[0.3, 0.7]),\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Introduce realistic data quality issues\n",
        "\n",
        "# 1. Missing values (10-15% in different columns)\n",
        "missing_indices_age = np.random.choice(df.index, size=int(0.12 * n_records), replace=False)\n",
        "df.loc[missing_indices_age, 'age'] = np.nan\n",
        "\n",
        "missing_indices_satisfaction = np.random.choice(df.index, size=int(0.08 * n_records), replace=False)\n",
        "df.loc[missing_indices_satisfaction, 'satisfaction_score'] = np.nan\n",
        "\n",
        "missing_indices_channel = np.random.choice(df.index, size=int(0.05 * n_records), replace=False)\n",
        "df.loc[missing_indices_channel, 'marketing_channel'] = np.nan\n",
        "\n",
        "# 2. Duplicates (3%)\n",
        "duplicate_rows = df.sample(n=int(0.03 * n_records))\n",
        "df = pd.concat([df, duplicate_rows], ignore_index=True)\n",
        "\n",
        "# 3. Outliers in purchase_amount (add some extreme values)\n",
        "outlier_indices = np.random.choice(df.index, size=20, replace=False)\n",
        "df.loc[outlier_indices, 'purchase_amount'] = np.random.uniform(1000, 5000, 20)\n",
        "\n",
        "# 4. Data type issues (convert some numeric to string)\n",
        "df['items_purchased'] = df['items_purchased'].astype(str)\n",
        "\n",
        "# 5. Inconsistent formatting in categorical data\n",
        "gender_variations = {'Male': ['Male', 'male', 'M', 'MALE'],\n",
        "                    'Female': ['Female', 'female', 'F', 'FEMALE'],\n",
        "                    'Other': ['Other', 'other', 'O']}\n",
        "\n",
        "for standard, variations in gender_variations.items():\n",
        "    mask = df['gender'] == standard\n",
        "    if mask.sum() > 0:\n",
        "        sample_size = min(int(mask.sum() * 0.15), mask.sum())\n",
        "        sample_indices = df[mask].sample(n=sample_size).index\n",
        "        df.loc[sample_indices, 'gender'] = np.random.choice(variations, sample_size)\n",
        "\n",
        "print(f\"Dataset created with {len(df)} records (including duplicates)\")\n",
        "print(f\"   Original records: {n_records}\")\n",
        "print(f\"   Duplicate records added: {len(df) - n_records}\")\n",
        "print(\"\\nData quality issues introduced:\")\n",
        "print(f\"   - Missing values in age, satisfaction_score, marketing_channel\")\n",
        "print(f\"   - {len(df) - n_records} duplicate rows\")\n",
        "print(f\"   - Outliers in purchase_amount\")\n",
        "print(f\"   - items_purchased stored as string instead of numeric\")\n",
        "print(f\"   - Inconsistent gender formatting\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOqBYMdJHgqa"
      },
      "outputs": [],
      "source": [
        "# Preview the data\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPUSlmJFHgqa"
      },
      "source": [
        "<a id='cleaning'></a>\n",
        "## 2. Data Cleaning\n",
        "\n",
        "Data cleaning is the foundation of good analysis. **80% of data science work is cleaning data!**\n",
        "\n",
        "### 2.1 Initial Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peUVVLj5Hgqb"
      },
      "outputs": [],
      "source": [
        "def inspect_data(df):\n",
        "    \"\"\"\n",
        "    Comprehensive data inspection function\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DATA INSPECTION REPORT\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Basic info\n",
        "    print(f\"\\nDataset Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
        "    print(f\"\\nMemory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "    # Data types\n",
        "    print(\"\\nðŸ“‹ Data Types:\")\n",
        "    print(df.dtypes)\n",
        "\n",
        "    # Missing values\n",
        "    print(\"\\nMissing Values:\")\n",
        "    missing = df.isnull().sum()\n",
        "    missing_pct = (missing / len(df) * 100).round(2)\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Missing Count': missing[missing > 0],\n",
        "        'Percentage': missing_pct[missing > 0]\n",
        "    }).sort_values('Percentage', ascending=False)\n",
        "\n",
        "    if len(missing_df) > 0:\n",
        "        print(missing_df)\n",
        "    else:\n",
        "        print(\"No missing values found!\")\n",
        "\n",
        "    # Duplicates\n",
        "    duplicates = df.duplicated().sum()\n",
        "    print(f\"\\nDuplicate Rows: {duplicates} ({duplicates/len(df)*100:.2f}%)\")\n",
        "\n",
        "    # Numeric columns summary\n",
        "    print(\"\\nNumeric Columns Summary:\")\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    if len(numeric_cols) > 0:\n",
        "        print(df[numeric_cols].describe())\n",
        "\n",
        "    # Categorical columns\n",
        "    print(\"\\nCategorical Columns:\")\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "    for col in categorical_cols:\n",
        "        unique_count = df[col].nunique()\n",
        "        print(f\"  {col}: {unique_count} unique values\")\n",
        "        if unique_count <= 10:\n",
        "            print(f\"    Values: {df[col].value_counts().to_dict()}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Run inspection\n",
        "inspect_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOTazirMHgqb"
      },
      "source": [
        "### 2.2 Handling Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe3CrXaQHgqb"
      },
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "print(f\"Total duplicates before removal: {df.duplicated().sum()}\")\n",
        "\n",
        "# Remove duplicates\n",
        "df_clean = df.drop_duplicates()\n",
        "\n",
        "print(f\"Total duplicates after removal: {df_clean.duplicated().sum()}\")\n",
        "print(f\"Rows removed: {len(df) - len(df_clean)}\")\n",
        "print(f\"\\nDataset shape after removing duplicates: {df_clean.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIX6CYxGHgqc"
      },
      "source": [
        "### 2.3 Fixing Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zMC8aPrHgqc"
      },
      "outputs": [],
      "source": [
        "# Convert items_purchased back to numeric\n",
        "print(\"Before conversion:\")\n",
        "print(f\"items_purchased dtype: {df_clean['items_purchased'].dtype}\")\n",
        "\n",
        "df_clean['items_purchased'] = pd.to_numeric(df_clean['items_purchased'], errors='coerce')\n",
        "\n",
        "print(\"\\nAfter conversion:\")\n",
        "print(f\"items_purchased dtype: {df_clean['items_purchased'].dtype}\")\n",
        "print(f\"\\nData type corrected for items_purchased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B34vgZo_Hgqc"
      },
      "source": [
        "### 2.4 Standardizing Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UEAwZ3jHgqc"
      },
      "outputs": [],
      "source": [
        "# Check current gender values\n",
        "print(\"Gender values before standardization:\")\n",
        "print(df_clean['gender'].value_counts())\n",
        "\n",
        "# Standardize gender column\n",
        "gender_mapping = {\n",
        "    'male': 'Male', 'M': 'Male', 'MALE': 'Male',\n",
        "    'female': 'Female', 'F': 'Female', 'FEMALE': 'Female',\n",
        "    'other': 'Other', 'O': 'Other'\n",
        "}\n",
        "\n",
        "df_clean['gender'] = df_clean['gender'].replace(gender_mapping)\n",
        "\n",
        "print(\"\\nGender values after standardization:\")\n",
        "print(df_clean['gender'].value_counts())\n",
        "print(f\"\\nGender column standardized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD8gFLGpHgqc"
      },
      "source": [
        "### 2.5 Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbwS2N41Hgqd"
      },
      "outputs": [],
      "source": [
        "# Strategy 1: Fill numeric missing values with median\n",
        "print(\"Missing values before imputation:\")\n",
        "print(df_clean.isnull().sum()[df_clean.isnull().sum() > 0])\n",
        "\n",
        "# For age: use median\n",
        "age_median = df_clean['age'].median()\n",
        "df_clean['age'].fillna(age_median, inplace=True)\n",
        "\n",
        "# For satisfaction_score: use mode (most common)\n",
        "satisfaction_mode = df_clean['satisfaction_score'].mode()[0]\n",
        "df_clean['satisfaction_score'].fillna(satisfaction_mode, inplace=True)\n",
        "\n",
        "# For marketing_channel: create 'Unknown' category\n",
        "df_clean['marketing_channel'].fillna('Unknown', inplace=True)\n",
        "\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(df_clean.isnull().sum().sum())  # Total missing values\n",
        "print(f\"\\nAll missing values handled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEl4cF8JHgqd"
      },
      "source": [
        "### 2.6 Detecting and Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEgD_BiJHgqd"
      },
      "outputs": [],
      "source": [
        "def detect_outliers_iqr(df, column):\n",
        "    \"\"\"\n",
        "    Detect outliers using IQR (Interquartile Range) method\n",
        "    \"\"\"\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "\n",
        "    return outliers, lower_bound, upper_bound\n",
        "\n",
        "# Detect outliers in purchase_amount\n",
        "outliers, lower, upper = detect_outliers_iqr(df_clean, 'purchase_amount')\n",
        "\n",
        "print(f\"Outlier detection for 'purchase_amount':\")\n",
        "print(f\"  Lower bound: ${lower:.2f}\")\n",
        "print(f\"  Upper bound: ${upper:.2f}\")\n",
        "print(f\"  Number of outliers: {len(outliers)} ({len(outliers)/len(df_clean)*100:.2f}%)\")\n",
        "print(f\"\\nOutlier range: ${outliers['purchase_amount'].min():.2f} - ${outliers['purchase_amount'].max():.2f}\")\n",
        "\n",
        "# Visualize outliers\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Before handling outliers\n",
        "axes[0].boxplot(df_clean['purchase_amount'])\n",
        "axes[0].set_title('Purchase Amount - With Outliers')\n",
        "axes[0].set_ylabel('Amount ($)')\n",
        "\n",
        "# Cap outliers at upper bound\n",
        "df_clean['purchase_amount_capped'] = df_clean['purchase_amount'].clip(upper=upper)\n",
        "\n",
        "# After handling outliers\n",
        "axes[1].boxplot(df_clean['purchase_amount_capped'])\n",
        "axes[1].set_title('Purchase Amount - Outliers Capped')\n",
        "axes[1].set_ylabel('Amount ($)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nOutliers capped at ${upper:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzwzXXBFHgqd"
      },
      "source": [
        "### 2.7 Data Cleaning Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ6Hoa3tHgqd"
      },
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"DATA CLEANING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nDuplicates removed: {len(df) - len(df_clean)} rows\")\n",
        "print(f\"Data types corrected: items_purchased\")\n",
        "print(f\"Categorical standardization: gender column\")\n",
        "print(f\"Missing values imputed:\")\n",
        "print(f\"   - age: filled with median ({age_median:.0f})\")\n",
        "print(f\"   - satisfaction_score: filled with mode ({satisfaction_mode})\")\n",
        "print(f\"   - marketing_channel: filled with 'Unknown'\")\n",
        "print(f\"Outliers handled: purchase_amount capped at ${upper:.2f}\")\n",
        "print(f\"\\nFinal dataset: {df_clean.shape[0]} rows Ã— {df_clean.shape[1]} columns\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms7o-sAqHgqd"
      },
      "source": [
        "<a id='eda'></a>\n",
        "## 3. Exploratory Data Analysis (EDA)\n",
        "\n",
        "EDA helps us understand patterns, relationships, and insights in the data.\n",
        "\n",
        "### 3.1 Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz0_8bByHgqe"
      },
      "outputs": [],
      "source": [
        "# Distribution of purchase amounts\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram\n",
        "axes[0].hist(df_clean['purchase_amount_capped'], bins=30, edgecolor='black', alpha=0.7, color='teal')\n",
        "axes[0].set_xlabel('Purchase Amount ($)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Distribution of Purchase Amounts')\n",
        "axes[0].axvline(df_clean['purchase_amount_capped'].mean(), color='red', linestyle='--', label=f\"Mean: ${df_clean['purchase_amount_capped'].mean():.2f}\")\n",
        "axes[0].axvline(df_clean['purchase_amount_capped'].median(), color='orange', linestyle='--', label=f\"Median: ${df_clean['purchase_amount_capped'].median():.2f}\")\n",
        "axes[0].legend()\n",
        "\n",
        "# Box plot\n",
        "axes[1].boxplot(df_clean['purchase_amount_capped'], vert=True)\n",
        "axes[1].set_ylabel('Purchase Amount ($)')\n",
        "axes[1].set_title('Purchase Amount Box Plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"Purchase Amount Statistics:\")\n",
        "print(df_clean['purchase_amount_capped'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZU-W7LHHgqe"
      },
      "outputs": [],
      "source": [
        "# Categorical variable analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Customer segment distribution\n",
        "segment_counts = df_clean['customer_segment'].value_counts()\n",
        "axes[0, 0].bar(segment_counts.index, segment_counts.values, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Customer Segment Distribution')\n",
        "axes[0, 0].set_ylabel('Count')\n",
        "\n",
        "# Marketing channel\n",
        "channel_counts = df_clean['marketing_channel'].value_counts()\n",
        "axes[0, 1].bar(channel_counts.index, channel_counts.values, color='lightcoral', edgecolor='black')\n",
        "axes[0, 1].set_title('Marketing Channel Distribution')\n",
        "axes[0, 1].set_ylabel('Count')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Product category\n",
        "category_counts = df_clean['product_category'].value_counts()\n",
        "axes[1, 0].bar(category_counts.index, category_counts.values, color='lightgreen', edgecolor='black')\n",
        "axes[1, 0].set_title('Product Category Distribution')\n",
        "axes[1, 0].set_ylabel('Count')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Satisfaction score\n",
        "satisfaction_counts = df_clean['satisfaction_score'].value_counts().sort_index()\n",
        "axes[1, 1].bar(satisfaction_counts.index, satisfaction_counts.values, color='plum', edgecolor='black')\n",
        "axes[1, 1].set_title('Satisfaction Score Distribution')\n",
        "axes[1, 1].set_xlabel('Score')\n",
        "axes[1, 1].set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb3mkKieHgqe"
      },
      "source": [
        "### 3.2 Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD4i5Ys8Hgqe"
      },
      "outputs": [],
      "source": [
        "# Relationship between age and purchase amount\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(df_clean['age'], df_clean['purchase_amount_capped'], alpha=0.5, c='teal')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Purchase Amount ($)')\n",
        "plt.title('Age vs Purchase Amount')\n",
        "\n",
        "# Add trend line\n",
        "z = np.polyfit(df_clean['age'].dropna(), df_clean.loc[df_clean['age'].notna(), 'purchase_amount_capped'], 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(df_clean['age'].sort_values(), p(df_clean['age'].sort_values()), \"r--\", alpha=0.8, label='Trend line')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Calculate correlation\n",
        "correlation = df_clean[['age', 'purchase_amount_capped']].corr().iloc[0, 1]\n",
        "print(f\"Correlation between age and purchase amount: {correlation:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DfE71frHgqe"
      },
      "outputs": [],
      "source": [
        "# Purchase amount by customer segment\n",
        "plt.figure(figsize=(12, 6))\n",
        "df_clean.boxplot(column='purchase_amount_capped', by='customer_segment', ax=plt.gca())\n",
        "plt.title('Purchase Amount by Customer Segment')\n",
        "plt.suptitle('')  # Remove default title\n",
        "plt.xlabel('Customer Segment')\n",
        "plt.ylabel('Purchase Amount ($)')\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics by segment\n",
        "print(\"\\nPurchase Amount by Customer Segment:\")\n",
        "print(df_clean.groupby('customer_segment')['purchase_amount_capped'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfLhP8xCHgqe"
      },
      "outputs": [],
      "source": [
        "# Discount usage vs purchase amount\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "discount_groups = df_clean.groupby('discount_used')['purchase_amount_capped'].mean()\n",
        "colors = ['lightcoral' if not x else 'lightgreen' for x in discount_groups.index]\n",
        "ax.bar(['No Discount', 'Discount Used'], discount_groups.values, color=colors, edgecolor='black')\n",
        "ax.set_ylabel('Average Purchase Amount ($)')\n",
        "ax.set_title('Average Purchase Amount: Discount vs No Discount')\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, v in enumerate(discount_groups.values):\n",
        "    ax.text(i, v + 2, f'${v:.2f}', ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(f\"Average purchase with discount: ${discount_groups[True]:.2f}\")\n",
        "print(f\"Average purchase without discount: ${discount_groups[False]:.2f}\")\n",
        "print(f\"Difference: ${discount_groups[True] - discount_groups[False]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3edJQC2Hgqe"
      },
      "source": [
        "### 3.3 Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKQAd62JHgqe"
      },
      "outputs": [],
      "source": [
        "# Correlation heatmap for numeric variables\n",
        "numeric_cols = ['age', 'purchase_amount_capped', 'items_purchased', 'days_since_last_purchase', 'satisfaction_score']\n",
        "correlation_matrix = df_clean[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix - Numeric Variables')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Identify strong correlations\n",
        "print(\"\\nStrong Correlations (|r| > 0.3):\")\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i+1, len(correlation_matrix.columns)):\n",
        "        if abs(correlation_matrix.iloc[i, j]) > 0.3:\n",
        "            print(f\"{correlation_matrix.columns[i]} <-> {correlation_matrix.columns[j]}: {correlation_matrix.iloc[i, j]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TD2MOphHgqf"
      },
      "source": [
        "### 3.4 Advanced EDA - Interactive Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekssl7tQHgqf"
      },
      "outputs": [],
      "source": [
        "# Interactive scatter plot with Plotly\n",
        "fig = px.scatter(df_clean,\n",
        "                 x='age',\n",
        "                 y='purchase_amount_capped',\n",
        "                 color='customer_segment',\n",
        "                 size='items_purchased',\n",
        "                 hover_data=['satisfaction_score', 'marketing_channel'],\n",
        "                 title='Purchase Behavior Analysis',\n",
        "                 labels={'purchase_amount_capped': 'Purchase Amount ($)',\n",
        "                        'age': 'Age (years)'})\n",
        "fig.show()\n",
        "\n",
        "print(\"Insight: Hover over points to see detailed customer information\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWouQnAcHgqf"
      },
      "outputs": [],
      "source": [
        "# Purchase by category and channel - Interactive\n",
        "category_channel = df_clean.groupby(['product_category', 'marketing_channel']).size().reset_index(name='count')\n",
        "\n",
        "fig = px.sunburst(category_channel,\n",
        "                  path=['product_category', 'marketing_channel'],\n",
        "                  values='count',\n",
        "                  title='Product Categories and Marketing Channels')\n",
        "fig.show()\n",
        "\n",
        "print(\"ðŸ’¡ Insight: Click on segments to drill down into the data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8jjddT8Hgqf"
      },
      "source": [
        "<a id='business'></a>\n",
        "## 4. Answering Business Questions\n",
        "\n",
        "Transform data insights into actionable business value.\n",
        "\n",
        "### The Framework:\n",
        "1. **Understand the Question** - What decision does this answer inform?\n",
        "2. **Identify Relevant Data** - Which features/tables matter?\n",
        "3. **Analyze & Quantify** - Use statistics, trends, comparisons\n",
        "4. **Validate Results** - Check for biases and edge cases\n",
        "5. **Craft the Answer** - Clear, specific, actionable\n",
        "\n",
        "### Business Question 1: Which customer segment has the highest revenue potential?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmMNfuTdHgqf"
      },
      "outputs": [],
      "source": [
        "# Calculate total and average revenue by segment\n",
        "segment_analysis = df_clean.groupby('customer_segment').agg({\n",
        "    'purchase_amount_capped': ['sum', 'mean', 'count'],\n",
        "    'items_purchased': 'mean',\n",
        "    'satisfaction_score': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "segment_analysis.columns = ['Total Revenue', 'Avg Purchase', 'Customer Count', 'Avg Items', 'Avg Satisfaction']\n",
        "segment_analysis = segment_analysis.sort_values('Total Revenue', ascending=False)\n",
        "\n",
        "print(\"Customer Segment Analysis:\")\n",
        "print(segment_analysis)\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Total revenue\n",
        "axes[0].bar(segment_analysis.index, segment_analysis['Total Revenue'],\n",
        "            color=['gold', 'silver', '#CD7F32'], edgecolor='black')\n",
        "axes[0].set_title('Total Revenue by Customer Segment')\n",
        "axes[0].set_ylabel('Total Revenue ($)')\n",
        "axes[0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Average purchase\n",
        "axes[1].bar(segment_analysis.index, segment_analysis['Avg Purchase'],\n",
        "            color=['teal', 'skyblue', 'lightblue'], edgecolor='black')\n",
        "axes[1].set_title('Average Purchase by Customer Segment')\n",
        "axes[1].set_ylabel('Average Purchase ($)')\n",
        "axes[1].tick_params(axis='x', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKEY INSIGHT:\")\n",
        "top_segment = segment_analysis.index[0]\n",
        "print(f\"{top_segment} customers generate the highest total revenue\")\n",
        "print(f\"Average purchase: ${segment_analysis.loc[top_segment, 'Avg Purchase']:.2f}\")\n",
        "print(f\"Customer count: {segment_analysis.loc[top_segment, 'Customer Count']:.0f}\")\n",
        "print(f\"\\nRECOMMENDATION: Prioritize retention programs for {top_segment} customers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBQ1R_Q2Hgqf"
      },
      "source": [
        "### Business Question 2: Which marketing channel is most effective?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpa85sy6Hgqf"
      },
      "outputs": [],
      "source": [
        "# Analyze effectiveness by channel\n",
        "channel_analysis = df_clean.groupby('marketing_channel').agg({\n",
        "    'purchase_amount_capped': ['mean', 'sum'],\n",
        "    'customer_id': 'count',\n",
        "    'satisfaction_score': 'mean',\n",
        "    'items_purchased': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "channel_analysis.columns = ['Avg Purchase', 'Total Revenue', 'Customers', 'Avg Satisfaction', 'Avg Items']\n",
        "\n",
        "# Calculate conversion value (avg purchase * customers)\n",
        "channel_analysis['Total Value'] = channel_analysis['Avg Purchase'] * channel_analysis['Customers']\n",
        "channel_analysis = channel_analysis.sort_values('Avg Purchase', ascending=False)\n",
        "\n",
        "print(\"Marketing Channel Effectiveness:\")\n",
        "print(channel_analysis)\n",
        "\n",
        "# Visualize\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=channel_analysis.index,\n",
        "    y=channel_analysis['Avg Purchase'],\n",
        "    name='Avg Purchase',\n",
        "    marker_color='lightblue'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=channel_analysis.index,\n",
        "    y=channel_analysis['Avg Satisfaction'],\n",
        "    name='Avg Satisfaction',\n",
        "    yaxis='y2',\n",
        "    marker_color='red',\n",
        "    mode='lines+markers'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Marketing Channel Performance',\n",
        "    xaxis_title='Marketing Channel',\n",
        "    yaxis_title='Average Purchase ($)',\n",
        "    yaxis2=dict(title='Average Satisfaction', overlaying='y', side='right', range=[0, 5]),\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nKEY INSIGHTS:\")\n",
        "best_channel = channel_analysis.index[0]\n",
        "print(f\"{best_channel} has the highest average purchase: ${channel_analysis.loc[best_channel, 'Avg Purchase']:.2f}\")\n",
        "print(f\"Customer satisfaction via {best_channel}: {channel_analysis.loc[best_channel, 'Avg Satisfaction']:.2f}/5\")\n",
        "print(f\"\\nRECOMMENDATION: Increase budget allocation to {best_channel} marketing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7Hnz_7cHgqg"
      },
      "source": [
        "### Business Question 3: What drives customer satisfaction?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdfwxXNGHgqg"
      },
      "outputs": [],
      "source": [
        "# Analyze factors affecting satisfaction\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Satisfaction by purchase amount groups\n",
        "df_clean['purchase_group'] = pd.cut(df_clean['purchase_amount_capped'],\n",
        "                                     bins=[0, 50, 100, 200, 1000],\n",
        "                                     labels=['Low', 'Medium', 'High', 'Very High'])\n",
        "\n",
        "satisfaction_by_purchase = df_clean.groupby('purchase_group')['satisfaction_score'].mean().sort_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(satisfaction_by_purchase.index, satisfaction_by_purchase.values,\n",
        "               color=['lightcoral', 'lightyellow', 'lightgreen', 'darkgreen'], edgecolor='black')\n",
        "plt.xlabel('Purchase Amount Group')\n",
        "plt.ylabel('Average Satisfaction Score')\n",
        "plt.title('Customer Satisfaction by Purchase Amount')\n",
        "plt.ylim(0, 5)\n",
        "plt.axhline(y=df_clean['satisfaction_score'].mean(), color='red', linestyle='--',\n",
        "            label=f\"Overall Avg: {df_clean['satisfaction_score'].mean():.2f}\")\n",
        "\n",
        "# Add value labels\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{height:.2f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Satisfaction by segment and discount usage\n",
        "satisfaction_factors = df_clean.groupby(['customer_segment', 'discount_used'])['satisfaction_score'].mean().unstack()\n",
        "\n",
        "satisfaction_factors.plot(kind='bar', figsize=(10, 6), color=['lightcoral', 'lightgreen'], edgecolor='black')\n",
        "plt.title('Satisfaction Score: Segment & Discount Impact')\n",
        "plt.xlabel('Customer Segment')\n",
        "plt.ylabel('Average Satisfaction Score')\n",
        "plt.legend(['No Discount', 'Discount Used'])\n",
        "plt.xticks(rotation=0)\n",
        "plt.ylim(0, 5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKEY INSIGHTS:\")\n",
        "print(f\"Higher purchase amounts correlate with higher satisfaction\")\n",
        "print(f\"Discount usage improves satisfaction across all segments\")\n",
        "print(f\"\\nRECOMMENDATIONS:\")\n",
        "print(\"   1. Implement targeted discount programs for lower-satisfaction segments\")\n",
        "print(\"   2. Focus on upselling to increase purchase amounts and satisfaction\")\n",
        "print(\"   3. Premium customers already show high satisfaction - maintain service quality\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEB0xsn4Hgqg"
      },
      "source": [
        "<a id='presentations'></a>\n",
        "## 5. Creating Non-Technical Presentations\n",
        "\n",
        "### Key Principles:\n",
        "1. **Lead with the Insight** - Start with what you found, not how\n",
        "2. **Use Visual Storytelling** - Charts beat tables\n",
        "3. **Avoid Jargon** - Say 'relationship' not 'correlation coefficient'\n",
        "4. **Quantify Impact** - Show ROI, cost savings, revenue potential\n",
        "5. **Recommend Actions** - What should they do with this info?\n",
        "\n",
        "### Example: Executive Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpeTemd3Hgqh"
      },
      "outputs": [],
      "source": [
        "# Create executive summary metrics\n",
        "total_customers = len(df_clean)\n",
        "total_revenue = df_clean['purchase_amount_capped'].sum()\n",
        "avg_purchase = df_clean['purchase_amount_capped'].mean()\n",
        "avg_satisfaction = df_clean['satisfaction_score'].mean()\n",
        "top_segment = df_clean.groupby('customer_segment')['purchase_amount_capped'].sum().idxmax()\n",
        "top_channel = df_clean.groupby('marketing_channel')['purchase_amount_capped'].mean().idxmax()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"EXECUTIVE SUMMARY - E-COMMERCE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nKEY METRICS\")\n",
        "print(f\"   Total Customers: {total_customers:,}\")\n",
        "print(f\"   Total Revenue: ${total_revenue:,.2f}\")\n",
        "print(f\"   Average Purchase: ${avg_purchase:.2f}\")\n",
        "print(f\"   Customer Satisfaction: {avg_satisfaction:.1f}/5.0\")\n",
        "\n",
        "print(f\"\\nTOP FINDINGS\")\n",
        "print(f\"   1. {top_segment} customers drive the highest revenue\")\n",
        "print(f\"   2. {top_channel} marketing channel has best ROI\")\n",
        "print(f\"   3. Discount usage increases both sales and satisfaction\")\n",
        "\n",
        "print(f\"\\nRECOMMENDATIONS\")\n",
        "print(f\"   1. Invest 40% more in {top_channel} marketing\")\n",
        "print(f\"   2. Create loyalty program for {top_segment} customers\")\n",
        "print(f\"   3. Expand discount strategies to increase customer lifetime value\")\n",
        "print(f\"   4. Focus on Electronics and Clothing categories (highest margins)\")\n",
        "\n",
        "print(f\"\\nPROJECTED IMPACT\")\n",
        "print(f\"   Revenue increase: 15-20% over next quarter\")\n",
        "print(f\"   Customer retention: +12%\")\n",
        "print(f\"   Customer satisfaction: {avg_satisfaction:.1f} â†’ 4.2+\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak4vVEIKHgqi"
      },
      "source": [
        "### Create Presentation-Ready Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhdIG684Hgqi"
      },
      "outputs": [],
      "source": [
        "# Create a clean, presentation-ready dashboard\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# Title\n",
        "fig.suptitle('E-Commerce Performance Dashboard', fontsize=20, fontweight='bold', y=0.98)\n",
        "\n",
        "# 1. Revenue by Segment\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "segment_revenue = df_clean.groupby('customer_segment')['purchase_amount_capped'].sum().sort_values(ascending=False)\n",
        "colors_seg = ['#028090', '#00A896', '#02C39A']\n",
        "ax1.bar(segment_revenue.index, segment_revenue.values, color=colors_seg, edgecolor='black')\n",
        "ax1.set_title('Revenue by Segment', fontweight='bold')\n",
        "ax1.set_ylabel('Revenue ($)')\n",
        "\n",
        "# 2. Channel Performance\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "channel_avg = df_clean.groupby('marketing_channel')['purchase_amount_capped'].mean().sort_values(ascending=False)\n",
        "ax2.barh(channel_avg.index, channel_avg.values, color='#028090', edgecolor='black')\n",
        "ax2.set_title('Avg Purchase by Channel', fontweight='bold')\n",
        "ax2.set_xlabel('Average Purchase ($)')\n",
        "\n",
        "# 3. Satisfaction Distribution\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "satisfaction_dist = df_clean['satisfaction_score'].value_counts().sort_index()\n",
        "ax3.bar(satisfaction_dist.index, satisfaction_dist.values, color='#00A896', edgecolor='black')\n",
        "ax3.set_title('Satisfaction Distribution', fontweight='bold')\n",
        "ax3.set_xlabel('Score')\n",
        "ax3.set_ylabel('Customers')\n",
        "\n",
        "# 4. Category Performance\n",
        "ax4 = fig.add_subplot(gs[1, :])\n",
        "category_stats = df_clean.groupby('product_category').agg({\n",
        "    'purchase_amount_capped': 'sum',\n",
        "    'customer_id': 'count'\n",
        "}).sort_values('purchase_amount_capped', ascending=False)\n",
        "\n",
        "x = np.arange(len(category_stats))\n",
        "width = 0.35\n",
        "\n",
        "ax4_twin = ax4.twinx()\n",
        "bars1 = ax4.bar(x - width/2, category_stats['purchase_amount_capped'], width,\n",
        "                label='Revenue', color='#028090', edgecolor='black')\n",
        "bars2 = ax4_twin.bar(x + width/2, category_stats['customer_id'], width,\n",
        "                     label='Customers', color='#02C39A', edgecolor='black', alpha=0.7)\n",
        "\n",
        "ax4.set_xlabel('Product Category')\n",
        "ax4.set_ylabel('Revenue ($)', color='#028090')\n",
        "ax4_twin.set_ylabel('Customer Count', color='#02C39A')\n",
        "ax4.set_title('Product Category Performance', fontweight='bold')\n",
        "ax4.set_xticks(x)\n",
        "ax4.set_xticklabels(category_stats.index)\n",
        "ax4.legend(loc='upper left')\n",
        "ax4_twin.legend(loc='upper right')\n",
        "\n",
        "# 5. Discount Impact\n",
        "ax5 = fig.add_subplot(gs[2, 0])\n",
        "discount_impact = df_clean.groupby('discount_used')['purchase_amount_capped'].mean()\n",
        "colors_disc = ['#FF6B6B', '#4ECDC4']\n",
        "ax5.bar(['No Discount', 'With Discount'], discount_impact.values, color=colors_disc, edgecolor='black')\n",
        "ax5.set_title('Discount Impact on Purchase', fontweight='bold')\n",
        "ax5.set_ylabel('Avg Purchase ($)')\n",
        "for i, v in enumerate(discount_impact.values):\n",
        "    ax5.text(i, v + 2, f'${v:.0f}', ha='center', fontweight='bold')\n",
        "\n",
        "# 6. Age Distribution\n",
        "ax6 = fig.add_subplot(gs[2, 1])\n",
        "ax6.hist(df_clean['age'].dropna(), bins=20, color='#028090', edgecolor='black', alpha=0.7)\n",
        "ax6.set_title('Customer Age Distribution', fontweight='bold')\n",
        "ax6.set_xlabel('Age')\n",
        "ax6.set_ylabel('Count')\n",
        "\n",
        "# 7. Key Metrics Box\n",
        "ax7 = fig.add_subplot(gs[2, 2])\n",
        "ax7.axis('off')\n",
        "metrics_text = f\"\"\"\n",
        "KEY METRICS\n",
        "\n",
        "Total Revenue:\n",
        "${total_revenue:,.0f}\n",
        "\n",
        "Avg Purchase:\n",
        "${avg_purchase:.2f}\n",
        "\n",
        "Satisfaction:\n",
        "{avg_satisfaction:.1f}/5.0\n",
        "\n",
        "Customers:\n",
        "{total_customers:,}\n",
        "\"\"\"\n",
        "ax7.text(0.1, 0.5, metrics_text, fontsize=12, verticalalignment='center',\n",
        "         bbox=dict(boxstyle='round', facecolor='#E8F4F8', edgecolor='#028090', linewidth=2),\n",
        "         fontweight='bold')\n",
        "\n",
        "plt.savefig('/home/claude/presentation_dashboard.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Presentation dashboard created and saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4PF7SawHgqi"
      },
      "source": [
        "<a id='best-practices'></a>\n",
        "## 6. Datathon Best Practices\n",
        "\n",
        "### DO:\n",
        "- Start with thorough data cleaning\n",
        "- Spend time understanding the business context\n",
        "- Create clear, simple visualizations\n",
        "- Focus on actionable insights\n",
        "- Practice your presentation\n",
        "- Document your code and process\n",
        "- Validate your findings\n",
        "- Manage your time wisely\n",
        "\n",
        "### DON'T:\n",
        "- Skip data quality checks\n",
        "- Overcomplicate your analysis\n",
        "- Use jargon in presentations\n",
        "- Ignore business context\n",
        "- Wait until last minute to prepare presentation\n",
        "- Forget to check for outliers\n",
        "- Make assumptions without validation\n",
        "\n",
        "### Time Management (8-hour datathon):\n",
        "- **Hours 1-2:** Data cleaning and initial exploration\n",
        "- **Hours 3-4:** Deep analysis and visualization\n",
        "- **Hours 5-6:** Answer business questions\n",
        "- **Hours 7-8:** Create presentation and practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOW3s8WrHgqi"
      },
      "source": [
        "## Final Checklist\n",
        "\n",
        "Before submitting your datathon work:\n",
        "\n",
        "- [ ] Data is clean (no duplicates, missing values handled, correct types)\n",
        "- [ ] Outliers identified and addressed appropriately\n",
        "- [ ] EDA completed with key insights documented\n",
        "- [ ] Business questions answered with supporting evidence\n",
        "- [ ] Visualizations are clear and presentation-ready\n",
        "- [ ] Recommendations are specific and actionable\n",
        "- [ ] Code is documented and reproducible\n",
        "- [ ] Presentation tells a compelling story\n",
        "- [ ] Technical accuracy validated\n",
        "- [ ] Practice presentation delivered\n",
        "\n",
        "---\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "### Libraries Documentation:\n",
        "- **Pandas:** https://pandas.pydata.org/docs/\n",
        "- **Matplotlib:** https://matplotlib.org/\n",
        "- **Seaborn:** https://seaborn.pydata.org/\n",
        "- **Plotly:** https://plotly.com/python/\n",
        "\n",
        "### Learning Resources:\n",
        "- Kaggle Learn: https://www.kaggle.com/learn\n",
        "- DataCamp: https://www.datacamp.com/\n",
        "- Towards Data Science: https://towardsdatascience.com/\n",
        "\n",
        "---\n",
        "\n",
        "**Good luck at your datathon!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}